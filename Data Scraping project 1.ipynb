{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "medieval-collector"
   },
   "source": [
    "# Web Scraping Project\n",
    "In this project, we are going to extract some information about all the products exposed on the website [Sephora](https://www.sephora.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "floppy-poetry"
   },
   "source": [
    "## We first begin by importing the most useful libraries.\n",
    "\n",
    "The first one is Selenium web driver.\n",
    "The second one is pandas, this will be used to store information as DataFrames.\n",
    "The third one, time.sleep, allows to wait some time for the explorer to download all the content.\n",
    "Lastly, we will use the datetime to deal with timestamps and time durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1618414590288,
     "user": {
      "displayName": "Slimane Latreche",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8M1_TlJ8QPtRvZLyosGzA7WV3Pcgr1HUugZPTA=s64",
      "userId": "08142413746093993250"
     },
     "user_tz": -60
    },
    "id": "spiritual-print"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2,\n",
    "        'permissions.default.image': 2, 'dom.ipc.plugins.enabled.libflashplayer.so': 'false'}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "collectible-spine"
   },
   "source": [
    "Now let's take a look at the website, you can see that all the brands are listed in **Brands ---> Brands A-Z**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "important-ottawa"
   },
   "source": [
    "![](brandsa-z.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adapted-evans"
   },
   "source": [
    "![](allbrands.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alone-arlington"
   },
   "source": [
    "Now, we want to extract the url for each brand, hence, we are going to inspect the brands names elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "collected-treatment"
   },
   "source": [
    "![](brand_name_elements.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "minute-creature"
   },
   "source": [
    "You can see that this elements have the following properties:\n",
    "1. *Tag* = 'a' \n",
    "2. *href* : The brand URL\n",
    "2. *class* = 'css-11medar e65zztl0'\n",
    "3. *text* : The brand name\n",
    "\n",
    "So, we are going to use the class to find out all the brands names and URLs\n",
    "\n",
    "\\* Since there are two classes *'css-11medar'* and *'e65zztl0'*, it's better to use the method ***find_elements_by_css_selector*** with th parameter *'.css-11medar.e65zztl0'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5933,
     "status": "ok",
     "timestamp": 1618414633878,
     "user": {
      "displayName": "Slimane Latreche",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8M1_TlJ8QPtRvZLyosGzA7WV3Pcgr1HUugZPTA=s64",
      "userId": "08142413746093993250"
     },
     "user_tz": -60
    },
    "id": "incorporate-wilderness"
   },
   "outputs": [],
   "source": [
    "url='https://www.sephora.com/brands-list'\n",
    "browser.get(url)\n",
    "sleep(1)\n",
    "brands_urls={}\n",
    "for item in browser.find_elements_by_css_selector('.css-11medar.e65zztl0'):\n",
    "    brands_urls[item.text]=item.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1618414641793,
     "user": {
      "displayName": "Slimane Latreche",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgM8M1_TlJ8QPtRvZLyosGzA7WV3Pcgr1HUugZPTA=s64",
      "userId": "08142413746093993250"
     },
     "user_tz": -60
    },
    "id": "modified-pierce",
    "outputId": "2e72ad9a-af10-4508-86db-22b5a4ed7a34"
   },
   "outputs": [],
   "source": [
    "brands_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "federal-meeting"
   },
   "source": [
    "Next, we are going to explore [the products of the first brand](https://www.sephora.com/brand/acqua-di-parma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "partial-richmond"
   },
   "outputs": [],
   "source": [
    "url=\"https://www.sephora.com/brand/acqua-di-parma\"\n",
    "browser.get(url)\n",
    "sleep(1)\n",
    "for k in range(1,100):\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight*k/100);\".replace('k',str(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shared-fundamentals"
   },
   "source": [
    "![](first_brand_product.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "relative-geneva"
   },
   "source": [
    "There are 46 products.\n",
    "\n",
    "Now, in order to get the urls of these products, let's inspect the first product element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opponent-danish"
   },
   "source": [
    "![](first_product_inspec.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "electrical-construction"
   },
   "source": [
    "This elements are characterized by the following properties:\n",
    "1. *Tag* = 'a' \n",
    "2. *href* : The product URL\n",
    "2. *class* = 'css-ix8km1'\n",
    "\n",
    "So, using the method ***find_elements_by_class_name()*** , we are going to find out all the products URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "competitive-marketplace",
    "outputId": "74f77feb-8a73-4226-ed0d-a2f55cb2482f"
   },
   "outputs": [],
   "source": [
    "product_urls=[]\n",
    "for item in browser.find_elements_by_class_name('css-ix8km1'):\n",
    "    product_urls.append(item.get_attribute('href'))\n",
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "still-ability"
   },
   "source": [
    "Next, let's follow [the first product link](https://www.sephora.com/product/blu-mediterraneo-mandorlo-di-sicilia-P307803?icid2=products%20grid:p307803)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prospective-medication"
   },
   "outputs": [],
   "source": [
    "url='https://www.sephora.com/product/blu-mediterraneo-mandorlo-di-sicilia-P307803?icid2=products%20grid:p307803'\n",
    "browser.get(url)\n",
    "sleep(2)\n",
    "for k in range(1,100):\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight*k/100);\".replace('k',str(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stopped-kruger"
   },
   "source": [
    "![](first_product.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "filled-retro"
   },
   "source": [
    "## Now, we have to scrape many deatils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pursuant-inquiry",
    "outputId": "247973eb-a14b-427a-8325-7a319a23fb23",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_reviews= int(browser.find_element_by_id(\"ratings-reviews-container\").find_element_by_tag_name('h2').text.split('(')[1][:-1])\n",
    "reviews=[]\n",
    "brand_url=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').get_attribute('href')\n",
    "brand_name=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').text\n",
    "prod_categ=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/nav/ol').text.replace('\\n','->')\n",
    "produ_name=browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/span\").text\n",
    "prod_price=float(browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/p/span/span[1]/b').text[1:])\n",
    "try:\n",
    "    prod_aver_star=float(browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/a[1]/div\").get_attribute('aria-label').split(' ')[0])\n",
    "except:\n",
    "    prod_aver_star=0\n",
    "prod_likes=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/div/span').text\n",
    "if prod_likes[-1]=='K':\n",
    "    prod_likes=int(float(prod_likes[:-1])*1000)\n",
    "else:\n",
    "    prod_likes=int(float(prod_likes))\n",
    "    \n",
    "print(num_reviews)\n",
    "while len(reviews)!=num_reviews:\n",
    "    for i in browser.find_elements_by_css_selector('.css-13o7eu2.eanm77i0'):\n",
    "        if len(i.find_elements_by_css_selector(\".css-1yc3bi7.eanm77i0\")):\n",
    "            review_text=i.find_element_by_css_selector(\".css-1x44x6f.eanm77i0\").text\n",
    "            star_rating=int(float(i.find_element_by_class_name('css-4qxrld').get_attribute('aria-label').split(' ')[0]))\n",
    "            review_date=i.find_element_by_css_selector('.css-ak0g49.eanm77i0').text\n",
    "            if 'm ago' in review_date:\n",
    "                review_date=datetime.now()-timedelta(minutes=int(review_date.split(' ')[0]))\n",
    "            elif 's ago' in review_date:\n",
    "                review_date=datetime.now()-timedelta(seconds=int(review_date.split(' ')[0]))\n",
    "            elif 'h ago' in review_date:\n",
    "                review_date=datetime.now()-timedelta(hours=int(review_date.split(' ')[0]))\n",
    "            elif 'd ago' in review_date:\n",
    "                review_date=datetime.now()-timedelta(days=int(review_date.split(' ')[0]))\n",
    "            else:\n",
    "                review_date=datetime.strptime(review_date, '%d %b %Y')\n",
    "\n",
    "            upvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[0].find_element_by_tag_name('span').text[1:-1])\n",
    "            downvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[1].find_element_by_tag_name('span').text[1:-1])\n",
    "            verified_purshase=bool(len(i.find_elements_by_css_selector(\".css-1cf4ane.eanm77i0\")))\n",
    "            recommanded=bool(len(i.find_elements_by_css_selector(\".css-12com3g.eanm77i0\")))\n",
    "            if len(i.find_elements_by_class_name( 'css-hoe9xz')):\n",
    "                shade_of_product=i.find_element_by_class_name( 'css-hoe9xz').text\n",
    "            else:\n",
    "                shade_of_product=''\n",
    "            \n",
    "            nickname=''\n",
    "            try:\n",
    "                nickname=i.find_element_by_tag_name('strong').text\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            eyes,hair,skin_col,skin_ty='','','',''            \n",
    "            try:\n",
    "                descr=i.find_element_by_css_selector(\".css-t72irq.eanm77i0\").text\n",
    "                eyes=descr.split(', ')[0]\n",
    "                hair=descr.split(', ')[1]\n",
    "                skin_col=descr.split(', ')[2]\n",
    "                skin_ty=descr.split(', ')[3]\n",
    "            except:\n",
    "                pass\n",
    "            reviews.append({'product name':produ_name, 'product average stars notation':prod_aver_star,'product likes':prod_likes,\n",
    "                            'product category': prod_categ, 'product price':prod_price,'product url':url,'brand name': brand_name, \n",
    "                            'brand URL':brand_url, 'review text':review_text,'review date':review_date, 'upvotes' :upvotes, 'downvotes':downvotes,\n",
    "                            'verified purshase':verified_purshase, 'recommanded':recommanded, 'shade of product':shade_of_product, \n",
    "                            'nickname':nickname,'eyes color':eyes,'hair color':hair, 'skin color':skin_col, 'skin type':skin_ty})\n",
    "            print(nickname+' : '+ str(star_rating))\n",
    "    \n",
    "    if len(reviews)!=num_reviews:\n",
    "        browser.find_element_by_class_name('css-2anst8').click()\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "national-collection"
   },
   "source": [
    "Different pieces of the code above are explained here\n",
    "\n",
    "1. The URL of the brand \n",
    "    ```python\n",
    "    brand_url=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').get_attribute('href')\n",
    "    ```\n",
    "    \n",
    "    \n",
    "2. The brand name\n",
    "    ```python\n",
    "    brand_name=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').text`\n",
    "    ```\n",
    "    \n",
    "    \n",
    "3. The product name\n",
    "    ```python\n",
    "    produ_name=browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/span\").text`\n",
    "    ```\n",
    "    \n",
    "4. The product price *(dollars)*\n",
    "    ```python\n",
    "    prod_price=float(browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/p/span/span[1]/b').text[1:])\n",
    "    ```\n",
    "    \n",
    "    \n",
    "5. The product category\n",
    "    ```python\n",
    "    prod_categ=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/nav/ol').text.replace('\\n','->')`\n",
    "    ```\n",
    "    \n",
    "    \n",
    "6. The product average stars notation\n",
    "    ```python\n",
    "    try:\n",
    "        prod_aver_star=float(browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/a[1]/div\").get_attribute('aria-label').split(' ')[0])\n",
    "    except:\n",
    "        prod_aver_star=0\n",
    "    ```\n",
    "    \n",
    "    \n",
    "7. The product likes number\n",
    "    ```python\n",
    "    prod_likes=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/div/span').text\n",
    "    ```\n",
    "\n",
    "\n",
    "   - Sometimes, this number contains a 'K' char which represents 1000, we then have to make some changes\n",
    "    ```python\n",
    "    if prod_likes[-1]=='K':\n",
    "        prod_likes=int(float(prod_likes[:-1])*1000)\n",
    "    else:\n",
    "        prod_likes=int(float(prod_likes))\n",
    "    ```\n",
    "    \n",
    "8. The number of reviews\n",
    "    ```python\n",
    "    num_reviews= int(browser.find_element_by_id(\"ratings-reviews-container\").find_element_by_tag_name('h2').text.split('(')[1][:-1])\n",
    "    ```\n",
    "    \n",
    "    \n",
    "9. The review text\n",
    "    ```python\n",
    "    review_text=i.find_element_by_css_selector(\".css-1x44x6f.eanm77i0\").text\n",
    "    ```\n",
    "   \n",
    "   \n",
    "10. The stars notation\n",
    "    ```python\n",
    "    star_rating=int(float(i.find_element_by_class_name('css-4qxrld').get_attribute('aria-label').split(' ')[0]))\n",
    "    ```\n",
    "    \n",
    "    \n",
    "11. The review date\n",
    "    ```python\n",
    "    review_date=i.find_element_by_css_selector('.css-ak0g49.eanm77i0').text\n",
    "    if 'm ago' in review_date:\n",
    "        review_date=datetime.now()-timedelta(minutes=int(review_date.split(' ')[0]))\n",
    "    elif 's ago' in review_date:\n",
    "        review_date=datetime.now()-timedelta(seconds=int(review_date.split(' ')[0]))\n",
    "    elif 'h ago' in review_date:\n",
    "        review_date=datetime.now()-timedelta(hours=int(review_date.split(' ')[0]))\n",
    "    elif 'd ago' in review_date:\n",
    "        review_date=datetime.now()-timedelta(days=int(review_date.split(' ')[0]))\n",
    "    else:\n",
    "        review_date=datetime.strptime(review_date, '%d %b %Y')\n",
    "    ```\n",
    "    \n",
    "    \n",
    "12. The review upvotes and downvotes\n",
    "    ```python\n",
    "    upvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[0].find_element_by_tag_name('span').text[1:-1])\n",
    "    downvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[1].find_element_by_tag_name('span').text[1:-1])\n",
    "    ```\n",
    "    \n",
    "    \n",
    "13. Purshase verification and recommandation\n",
    "    ```python\n",
    "    verified_purshase=bool(len(i.find_elements_by_css_selector(\".css-1cf4ane.eanm77i0\")))\n",
    "    recommanded=bool(len(i.find_elements_by_css_selector(\".css-12com3g.eanm77i0\")))\n",
    "    ```\n",
    "    \n",
    "    \n",
    "14. The shade of th product *(if available)*\n",
    "    ```python\n",
    "    if len(i.find_elements_by_class_name( 'css-hoe9xz')):\n",
    "        shade_of_product=i.find_element_by_class_name( 'css-hoe9xz').text\n",
    "    else:\n",
    "        shade_of_product=''\n",
    "    ```\n",
    "    \n",
    "    \n",
    "15. Reviewer details\n",
    "    ```python\n",
    "    nickname=''\n",
    "    try:\n",
    "        nickname=i.find_element_by_tag_name('strong').text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    eyes,hair,skin_col,skin_ty='','','',''            \n",
    "    try:\n",
    "        descr=i.find_element_by_css_selector(\".css-t72irq.eanm77i0\").text\n",
    "        eyes=descr.split(', ')[0]\n",
    "        hair=descr.split(', ')[1]\n",
    "        skin_col=descr.split(', ')[2]\n",
    "        skin_ty=descr.split(', ')[3]\n",
    "    except:\n",
    "        pass\n",
    "    ```\n",
    "    \n",
    "    \n",
    "- The last piece of code aims to click on 'next' arrow *(See the figure below)*\n",
    "    ```python\n",
    "    if len(reviews)!=num_reviews:\n",
    "        browser.find_element_by_class_name('css-2anst8').click()\n",
    "        sleep(5)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spectacular-treat"
   },
   "source": [
    "![](next_arrow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "express-innocent"
   },
   "source": [
    "Next, we make all the code above in a single function, that takes a product URL and returns the information as a list of dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stuck-punch"
   },
   "outputs": [],
   "source": [
    "def extract_details(url):\n",
    "    browser.get(url)\n",
    "    sleep(2)\n",
    "    for k in range(1,100):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight*k/100);\".replace('k',str(k)))\n",
    "    \n",
    "    reviews=[]\n",
    "    num_reviews= int(browser.find_element_by_id(\"ratings-reviews-container\").find_element_by_tag_name('h2').text.split('(')[1][:-1])\n",
    "    brand_url=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').get_attribute('href')\n",
    "    brand_name=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/a').text\n",
    "    prod_categ=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/nav/ol').text.replace('\\n','->')\n",
    "    produ_name=browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/h1/span\").text\n",
    "    prod_price=float(browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/p/span/span[1]/b').text[1:])\n",
    "    try:\n",
    "        prod_aver_star=float(browser.find_element_by_xpath(\"/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/a[1]/div\").get_attribute('aria-label').split(' ')[0])\n",
    "    except:\n",
    "        prod_aver_star=0\n",
    "    prod_likes=browser.find_element_by_xpath('/html/body/div[1]/div[2]/div/main/div/div[1]/div[1]/div/div/span').text\n",
    "    if prod_likes[-1]=='K':\n",
    "        prod_likes=int(float(prod_likes[:-1])*1000)\n",
    "    else:\n",
    "        prod_likes=int(float(prod_likes))\n",
    "\n",
    "    while len(reviews)!=num_reviews:\n",
    "        for i in browser.find_elements_by_css_selector('.css-13o7eu2.eanm77i0'):\n",
    "            if len(i.find_elements_by_css_selector(\".css-1yc3bi7.eanm77i0\")):\n",
    "                review_text=i.find_element_by_css_selector(\".css-1x44x6f.eanm77i0\").text\n",
    "                star_rating=int(float(i.find_element_by_class_name('css-4qxrld').get_attribute('aria-label').split(' ')[0]))\n",
    "                review_date=i.find_element_by_css_selector('.css-ak0g49.eanm77i0').text\n",
    "                if 'm ago' in review_date:\n",
    "                    review_date=datetime.now()-timedelta(minutes=int(review_date.split(' ')[0]))\n",
    "                elif 's ago' in review_date:\n",
    "                    review_date=datetime.now()-timedelta(seconds=int(review_date.split(' ')[0]))\n",
    "                elif 'h ago' in review_date:\n",
    "                    review_date=datetime.now()-timedelta(hours=int(review_date.split(' ')[0]))\n",
    "                elif 'd ago' in review_date:\n",
    "                    review_date=datetime.now()-timedelta(days=int(review_date.split(' ')[0]))\n",
    "                else:\n",
    "                    review_date=datetime.strptime(review_date, '%d %b %Y')\n",
    "\n",
    "                upvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[0].find_element_by_tag_name('span').text[1:-1])\n",
    "                downvotes =int(i.find_elements_by_class_name(\"css-36ie0l\")[1].find_element_by_tag_name('span').text[1:-1])\n",
    "                verified_purshase=bool(len(i.find_elements_by_css_selector(\".css-1cf4ane.eanm77i0\")))\n",
    "                recommanded=bool(len(i.find_elements_by_css_selector(\".css-12com3g.eanm77i0\")))\n",
    "                if len(i.find_elements_by_class_name( 'css-hoe9xz')):\n",
    "                    shade_of_product=i.find_element_by_class_name( 'css-hoe9xz').text\n",
    "                else:\n",
    "                    shade_of_product=''\n",
    "\n",
    "                nickname=''\n",
    "                try:\n",
    "                    nickname=i.find_element_by_tag_name('strong').text\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                eyes,hair,skin_col,skin_ty='','','',''            \n",
    "                try:\n",
    "                    descr=i.find_element_by_css_selector(\".css-t72irq.eanm77i0\").text\n",
    "                    eyes=descr.split(', ')[0]\n",
    "                    hair=descr.split(', ')[1]\n",
    "                    skin_col=descr.split(', ')[2]\n",
    "                    skin_ty=descr.split(', ')[3]\n",
    "                except:\n",
    "                    pass\n",
    "                reviews.append({'product name':produ_name, 'product average stars notation':prod_aver_star,'product likes':prod_likes,\n",
    "                                'product category': prod_categ, 'product price':prod_price,'product url':url,'brand name': brand_name, \n",
    "                                'brand URL':brand_url, 'review text':review_text,'review date':review_date, 'upvotes' :upvotes, 'downvotes':downvotes,\n",
    "                                'verified purshase':verified_purshase, 'recommanded':recommanded, 'shade of product':shade_of_product, \n",
    "                                'nickname':nickname,'eyes color':eyes,'hair color':hair, 'skin color':skin_col, 'skin type':skin_ty})\n",
    "\n",
    "        if len(reviews)!=num_reviews:\n",
    "            browser.find_element_by_class_name('css-2anst8').click()\n",
    "            sleep(1)\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the job done, we proceed like this:\n",
    "\n",
    "- Instantiate a pandas DataFrame object `results`\n",
    "- For each brand in the dictionary of brands: `brands_urls`\n",
    "    - Find out the list of products urls\n",
    "    - For each product url in the list in question\n",
    "        - Extract the details using `extract_details(url)`\n",
    "        - Add the extracted information into `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(columns=['product name', 'product average stars notation','product likes'\n",
    "                         ,'product category', 'product price','product url','brand name', \n",
    "                         'brand URL', 'review text','review date', 'upvotes' , 'downvotes',\n",
    "                         'verified purshase', 'recommanded','shade of product','nickname',\n",
    "                         'eyes color','hair color', 'skin color', 'skin type'])\n",
    "for brand_url in brands_urls.values():\n",
    "    print(brand_url)\n",
    "    browser.get(brand_url)\n",
    "    sleep(1)\n",
    "    for k in range(1,100):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight*k/100);\"\n",
    "                               .replace('k',str(k)))\n",
    "    product_urls=[]\n",
    "    for item in browser.find_elements_by_class_name('css-ix8km1'):\n",
    "        product_urls.append(item.get_attribute('href'))\n",
    "    for url in product_urls:\n",
    "        print(url)\n",
    "        try:\n",
    "            reviews=extract_details(url)\n",
    "        except :\n",
    "            continue\n",
    "\n",
    "        for review in reviews:\n",
    "            results=results.append(review, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell above looks sufficient to accommpish the task. But, one may get some network or power issues since there are many brands and many products, so the operation will take a lot of time.\n",
    "\n",
    "To overcome this possible problem, one way to take is as follows:\n",
    "1. Create an empty Excel file `results.xlsx`\n",
    "2. Read the excel file to a DataFrame, and extract the lists of the products urls\n",
    "    ```python\n",
    "    old_results=pd.read_excel('results.xlsx')\n",
    "    got_url = old_results['product url'].tolist()\n",
    "    ```\n",
    "3. Run the cell conaining the extraction code\n",
    "    ```python\n",
    "    results=pd.DataFrame(columns=['product name', 'product average stars notation', \n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "                for review in reviews:\n",
    "                    results=results.append(review, ignore_index=True)\n",
    "    ```\n",
    "    \n",
    "4. If somehow the cell stops working, save the extracted information\n",
    "    ```python\n",
    "    results.to_excel('results.xlsx')\n",
    "    ```\n",
    "5. Repeat the steps ***2***, ***3*** and ***4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results=pd.read_excel('results.xlsx')\n",
    "got_url= old_results['product url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(columns=['product name', 'product average stars notation','product likes'\n",
    "                         ,'product category', 'product price','product url','brand name', \n",
    "                         'brand URL', 'review text','review date', 'upvotes' , 'downvotes',\n",
    "                         'verified purshase', 'recommanded','shade of product','nickname',\n",
    "                         'eyes color','hair color', 'skin color', 'skin type'])\n",
    "results.append(old_results)\n",
    "for brand_url in brands_urls.values():\n",
    "    print(brand_url)\n",
    "    browser.get(brand_url)\n",
    "    sleep(1)\n",
    "    for k in range(1,100):\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight*k/100);\"\n",
    "                               .replace('k',str(k)))\n",
    "    product_urls=[]\n",
    "    for item in browser.find_elements_by_class_name('css-ix8km1'):\n",
    "        product_urls.append(item.get_attribute('href'))\n",
    "    for url in product_urls:\n",
    "        if url not in got_url:\n",
    "            print(url)\n",
    "            try:\n",
    "                reviews=extract_details(url)\n",
    "                got_url.append(url)\n",
    "            except :\n",
    "                continue\n",
    "\n",
    "            for review in reviews:\n",
    "                results=results.append(review, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.to_excel('results.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Upwork_Project_07_04_2021_Scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
